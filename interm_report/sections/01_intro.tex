\section*{Introduction}
Counterfactuals are established as one of the main approaches in explainable AI (XAI). They offer the user insight on how model decisions are made, by providing counterfactual examples of a sample, showing the changes in feature values needed for that sample to be labeled differently. 


There are many papers written that focus on the process of generating counterfactuals with a wide variety of approaches~\cite{keane2020good}, but far less papers that focus on the visualisation aspects. Most visualisation methods found in literature present either underdeveloped or overly complex user interfaces, rely on a specific counterfactual generator or do not validate their method with a user study. This research aims to address these shortcomings by developing a user-friendly, model agnostic counterfactual visualization method.

\subsection*{Related works}
From the counterfactual visualisation methods we looked at, we really liked the approach of SDA-Vis \cite{garcia2022sda} which is a great visualisation and unlike most other papers they did a simple user study. Still we feel can the UI be a bit convoluted and that it is focused in a specific domain. It does have the potential to generalise but we believe it needs some getting used to and is more tailored somewhat more expert users which is not what our goal of simplicity is. 

AdViCE \cite{gomez2021advice} and DECE \cite{cheng2020dece} are two other examples of tools that visualise counterfactuals but are either by design or ended up being not suitable for end users.

Simpler UIs we looked at are ViCE \cite{gomez2020vice} which only works with numeric values and an attempt at an improvement \cite{guyomard2023interactive} which has a similar interface but supports categorical values. The issue we found with their approach is that it does not scale well if we increase the number of features as the interface will start displaying too much information and this becomes less interpretable. The densities of variables used as coloring in ViCE can also be confusing and hard to understand. 

In the visualisation tool proposed by Guyomard et al. \cite{guyomard2023interactive} counterfactuals need to be generated beforehand and input as a json format which makes the solution counterfactual model-agnostic but can require an expert to use. 

An issue with all the UIs we mentioned so far is that they do not take into account psychological aspects. The authors of \cite{warren2022better} argue that based on a study users have an easier time interpreting categorical values compared to continuous numbers so it might be a better idea to divide continuous values into bins or ranges..

\subsection*{Purpose}
Based on our research in our paper we plan to develop a counterfactual model-agnostic UI with a focus on end-users and with as little expert intervention as possible for initial configuration. We want a streamlined user experience that makes the process of generating and understanding counterfactuals as easy as possible. We will work with tabular data containing both continuous and categorical features and we test and improve on the psychological approach suggested in \cite{warren2022better} by using configurable binning and performing a user study to validate the results.